---
title: A Simple Statistical Inference Example - Coin Flip
tags: [singular-learning-theory, machine-learning, statistics]
categories: [singular-learning-theory-lecture-series]
description: 
date: 2022-01-13
math: true
image: 
  src: /2022-01-13/coin-flipping-demon-model2.jpg
  width: 100%
#   height: 50
  alt: image not found
---
<!-- <iframe src="https://drive.google.com/file/d/1M0acGY5taIJJmUmsl82LyzzkVK-PqeGn/preview" width="100%" height="50" allow="autoplay"></iframe> -->

<div class=epi>
  <blockquote>
    â€œIt is simplicity itself, so absurdly simple that an explanation is superfluous; and yet it may serve to define the limits of observation and of deduction."
    <cite>Sherlock Holmes, "The Sign of Four"</cite>
  </blockquote>
</div>

In this post, a simple statistical inference task, that of a modeling a coin flip, shall be our vehicle to introduce important statistical concepts that will become central to our study. We shall show our calculations with excruciating details in hope that such simple case will be instructive and serve to define the limits of our tools in extracting exact results. 

<details>
  <summary> Post summary: </summary>
  <p>
    To model the outcome of a coin flip, we introduce a general way to do statistical inference by constructing a <b>parameterised model</b> - a family of probability distributions, each a possible approximation to the process that generates the coin flips. We introduce the <b> likelihood function </b> which the probability of observing the given data set assuming they are generated by the model at a specified parameter. 
  </p>

  <p>
    We introduce a popular statistical estimation method, the <b>Maximum Likelihood</b> method to estimate the outcome of a coin flip, where the likelihood function is treated as an objective function to be maximised and the model at the maximum is used to approximate the truth. We point out that <b>the result of such an inference procedure is itself random</b>. Specifically, it depends on the random sampling that generates the data set. It is the role of a <b>statistical learning theory</b> to clarify if a certain statistical estimation procedure is to be employed
    <ul>
      <li>What is the expected performance given subject to the randomness of training samples?</li>
      <li>For what class of true data generating process would the procedure approximate well?</li>
    </ul>
  </p>

  <p>
    Using the normal approximation to the binomial distribution, we shall see that the maximum likelihood estimator for the coin flip model is <b>asymptotically normal</b> and <b>asymptotically efficient</b> two desirable properties that is the hallmark of <b>regular model</b> but are absent from <b>singular models</b>. 
  </p>
</details>

- [The Situation, The Dataset](#the-situation-the-dataset)
- [Statistical Inference](#statistical-inference)
  - [Models](#models)
  - [Learning and Inference](#learning-and-inference)
- [The Adventure of Maximum Likelihood Estimation](#the-adventure-of-maximum-likelihood-estimation)
  - [Empirical Log Loss and Log Likelihood Ratio](#empirical-log-loss-and-log-likelihood-ratio)
  - [Finally Some Calculations](#finally-some-calculations)
  - [So how did we do?](#so-how-did-we-do)
- [A Broader Theory of MLE and Fisher Information](#a-broader-theory-of-mle-and-fisher-information)
- [Role of Statistical Learning Theory](#role-of-statistical-learning-theory)
- [Conclusion](#conclusion)


# The Situation, The Dataset 
Suppose there is a coin-flipping demon on the other side of a door. He offers us a deal. We can bet a number of years of our remaining life, if his next coin flip turns out to be head, he will pay us double what we bet. Otherwise, he keeps the bet. Rather uncharacteristically<span sidenote>or maybe it's just a deception</span>, he offers to first perform $N$ flips and let us look at the results. We shall call this set of observations 

$$
D_N = \set{X_1, X_2, \dots, X_N}
$$

where $X_i \in \set{H, T}$ our **dataset**. As a pure utilitarian, we decide to not run. Which means we better have a really good estimate of the probability $\hat{p}$ of the next flip turning out head <span sidenote> since most sound betting strategy relies on it. For instance, the <a href="https://en.wikipedia.org/wiki/Kelly_criterion">Kelly's criterion </a> gives the optimal fraction of our life in this situation as $2 \hat{p} - 1$ </span>. 


# Statistical Inference

## Models
So we are in a situation where we are given a _training set_ of previous coin flips, $D_N$ and our task is to estimate the probability $\hat{p}$ that the next flip comes up head. 

Let $h$ denote the number of heads in the dataset $D_N$ and $t = N - h$ the number of tails.

<p class=block>
  <b>Model 0. </b> We can simply <i>guess</i> that it's a fair coin so that $\hat{p} = 1/2$. This is a not a good inference method<span sidenote> not less because a demon wouldn't be <i>fair</i></span>. There is no <i>learning</i> involved at all. We ignored the dataset, a valuable resource in dealing with a demon. 

  Even in this case, we are still left with the task of finding out <i>when</i> is this method bad<span sidenote>just so that no one will come and say "I told you so" when the demon actually uses a fair coin</span> and quantifying exactly how bad the method.  
</p>

<p class=block>
  <b>Model 1. </b> We can instead construct a family of hypothesis, parameterised by $w \in [0, 1]$. Each $w$ represent a guess that the probability of landing head $=w$. We say that we are defining a <span def>model</span> 
  
  $$p(H \mid w) = w$$ 
  
  with <span def>parameter</span> $w$ taking value in the <span def>parameter space</span> $W = [0, 1]$. We can now reason as follow: <br/>
  <i>
    If the probability of landing head were to be $w$, then the probability that the dataset $D_N$ that we observed get generated is 
    $$
      p(D_N \mid w) = \prod_{i = 1}^N p(X_i \mid w) = w^h (1 - w)^t.
    $$
  </i><br/><br/>

  Notice that we are <i>assuming </i> that, on the other side of the door, the demon is consistently throwing the same coin with a constant probability of landing heads and throwing it in the same way. We call the true probability of landing head the <span def>true parameter $w_0$</span>. This means that each $X_i$ follows <span def>identical</span> distribution, $p(H) = w_0$, and that each observation is <span def>independent</span> of all others. Together is the common <span def>independent and identically distributed (i.i.d)</span> assumption that allow us to factorise $p(D_N\mid w)$ as we did above<span sidenote>We could stipulate additionally that the order of $X_i$ doesn't matter, introducing a factor of $\binom{N}{h}$ making the above the <a href="https://en.wikipedia.org/wiki/Binomial_distribution#Definitions">binomial distribution</a>. But we omit this for exposition uniformity. The binomial coefficient will be reintroduced whenever we sum over these sequences anyway. </span>. We call the probability of observing a given dataset for a given parameter the <span def>likelihood function</span>
  
  $$l_N(w) = p(D_N \mid w)$$

  which, to emphasise, is a function of paramter $w$ with the dataset $D_N$ fixed.
</p>


<p class=block>
  <b>Model 2. </b> But the demon could be more ... demonic. Every time he does a flip, he could've been choosing one of two coins at random from a box, only one of which is a fair coin. We can introduce another parameter $s \in [0,1]$ for representing the probability that the fair coin is chosen and $w \in [0, 1]$ represent the bias - probability of landing heads - for the other coin. We have now a two dimensional<span sidenote>but still compact</span> paramter space $(s, w) \in [0, 1]^2$. The hypothesis at each parameter is given by
    $$
      \begin{align*}
        p(H \mid s, w) &= \frac{1}{2}s + w (1 -s) \\
        p(T \mid s, w) &= \frac{1}{2}s + (1 - w) (1 - s) 
      \end{align*}
    $$
  and the likelihood function becomes
    $$
      l_N(w) = \prod_{i = 1}^Np(X_i \mid s, w) = \brac{\frac{1}{2}s + w (1 -s)}^h \brac{\frac{1}{2}s + (1 - w)(1 -s)}^t
    $$
  which again uses the i.i.d assumption. 
</p>


## Learning and Inference
We could continue to imagine more and more demonic opponent on the other side, but we should figure out what good can the above model do. 

We can continue the reasoning with likelihood function as follow: 

<i> 
  We now have $l_N$ giving us the probability of observing $D_N$ for specific parameter.  
  Surely the most likely $w$ is the one that give the highest probability for the observed data?<span sidenote> this reminds me a little of the <a href="https://en.wikipedia.org/wiki/Anthropic_principle">antropic principle.</a></span> Hence we should set the estimate $\hat{p}$ to be the parameter $w$ that maximises $l_N(w)$.
</i>


This gives us the statistical inference method known as <span def>Maximum Likelihood Estimate (MLE)</span>, i.e. find the single parameter <span sidenote>this makes it a <i>point estimate.</i></span> $w$ that maximises the likelihood function. 

This is a natural line of reasoning<span sidenote>there was a time when I was only taught this method of statistical estimation and think this is the only way.</span>, and indeed it is in some sense the correct method for this situation. 

However, MLE assumed quite a few things. 
 * MLE says "surely another coin with a different probability of landing heads would produce quite different looking observations $D_N$?". Well, not really. What if there is only one observation $N = 1$? Let's say $D_1 = \set{H}$. Surely a whole range of $w$ could've plausibly generated it<span sidenote>as we shall see, the MLE answer in this case would be at the boundary of $[0, 1]$, $\hat{p} = 1$ which, at least to me, doesn't seem to be a well-justified answer.</span>? 
 * "Ah, but if $N$ is truly huge, small difference in $w$ will result in very different $D_N$", says MLE. We shall see that this is indeed true. As the number of observations grow, it becomes **asymptotically** impossible for another parameter but the true one to generate the sequence of coin flips observed. 
 * BUT, that is only true if we made the assumption that the true parameter is contained in the model! This is the <span def>realisability</span> assumption. For instance, if the demon is really following the coin flipping recipe laid out in model 2 above, then maximising the likelihood function of model 1<span sidenote> how much worse is model 0?</span>wouldn't give us accurate answer, not even asymptotically. 
 * MLE doesn't provide the answer to the quenstion "what is the most likely parameter given the observation" $= p(w \mid D_N)$, which is a distinct question to "what is the most likely observation given the parameter" $= p(D_N \mid w)$. 

# The Adventure of Maximum Likelihood Estimation
Despite the above misgiving, we shall push through with MLE of model 1. We shall have explicit computation and introduce several important statistical concepts along the way. We shall see in what sense is MLE a good estimator in this case and what could go wrong in other situations where we might like to use the same procedure. 

We shall also make the realisability assumption where the demon's coin flip follows the following true distribution 

$$
\begin{align*}
  q(H) &= w_0 \\
  q(T) &= (1 - w_0)
\end{align*}
$$

for some true paramter $w_0 \in [0, 1]$. Meaning $q(x) = p(x \mid w_0)$. 

## Empirical Log Loss and Log Likelihood Ratio
We wish to set $\hat{p} =$ the maximum of the likelihood function

$$
  l_N(w) = w^h (1 - w)^t.
$$

If $N$ is a large number, the above expression produces really small numbers which can be numerically challenging to handle. We usually do a monotonic<span sidenote> hence doesn't change any extrema of the function </span>transform by taking its logarithm, which also happily simplifies several calculations. In fact, we shall introduce the <span def>empirical log loss function</span>

$$
  L_N(w) = -\frac{1}{N} \log p(D_N \mid w) = -\frac{1}{N} \sum_{i = 1}^N \log p(X_i \mid w) 
$$

which we shall aim to _minimise_<span sidenote>hence the usage of the term "loss".</span>. In our case, we get

$$
  L_N(w) = \frac{1}{N} \brac{\sum_{X_i = H} \log w + \sum_{X_i = T} \log (1 - w)} = \frac{1}{N} \sqbrac{h \log w + t \log (1 - w)}
$$


Below is a little tangent justifying the introduction of this quantity and its connection to the log likelihood ratio function which will be an important information theoretic quantity for our study.

<details open>
  <summary>Connection to log likelihood ratio</summary>
  <p>
    The <a href="https://en.wikipedia.org/wiki/Entropy_(information_theory)#Definition">Shanon entropy </a>of the true distribution is given by 
    
    $$
      S(q) = -\E_q(\log q(X)) = -q(H)\log q(H) + -q(T) \log q(T) 
    $$
    
    which can be approximated by the <span def>empirical entropy</span> using the observation from the data set $D_N$ 
    
    $$
      S_N(q) = -\frac{1}{N} \sum_{i = 1}^N \log q(X_i).
    $$

    Adding this quantity to the empirical log loss function we get the <span def>empirical log likelihood ratio </span>
    
    $$
      K_N(w) = \frac{1}{N} \sum_{i = 1}^N \log \frac{q(X_i)}{p(X_i \mid w)} = -\frac{1}{N} \sum_{i = 1}^N \log p(X_i \mid w) + \frac{1}{N} \sum_{i = 1}^N \log q(X_i) = L_N(w) - S_N(q)
    $$

    which is the empirical estimate to the central object of study, the <span def> expected log likelihood rato</span> better known as the <span def> <a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">Kullback-Leibler divergence</a></span> of the model at $w$ to the true distribution

    $$
      K(w) = D_{KL}(q(x) \mid \mid p(x \mid w)) = \E_X\sqbrac{\log \frac{q(X)}{p(X \mid w)}}. 
    $$ 

    We note that minimising $K_N(w)$ is equivalent to minimising $L_N(w)$ since they differ by an additive constant that is independent of $w$. 
  </p>
</details>

## Finally Some Calculations
Since our objective function $L_N(w)$ is a differentiable function, we shall use the stationary point criterion for finding local minima. 


<iframe src="https://drive.google.com/file/d/1L8MurEGH8YJzsSwzsUybbcxhfJOcUHvb/preview" title="Minimising average log loss."></iframe>

So, we find that maximimum likelihood estimate is given by

$$
\hat{p} = \hat{w} = \frac{h}{N}.
$$

It's important to emphasise again that $h$ in the expression above is the number of heads in the given data set $D_N$, _it depends on the given set of observations so is itself a random variable!_<span sidenote>indeed, even functions we defined like $l_N(w)$, $L_N(w)$, $K_N(w)$ are all random variables, they just take values in the space of functions. This is why proper investigation into their behaviour in statistical learning theory requires functional analysis. </span> 

## So how did we do? 
Though we now have our estimate, there is still a concern that we might have gotten an atypical data set which makes our guess wildly inaccurate. We need some way to quantify the uncertainty of our $\hat{w} = h / N$ estimate. Fortunately, we can do some exact calculation in this case. 

<iframe src="https://drive.google.com/file/d/1BiPdUnsiFyvqI-nsOpYpGEtwH0og-gv0/preview"></iframe>


The asymptotic normality $\hat{w} \to N(Nw_0, Nw_0 (1 - w_0))$ uses the [normal approximation to binomial distribution](https://en.wikipedia.org/wiki/Binomial_distribution#Normal_approximation).<span sidenote> can be proven by apply the <a href="https://en.wikipedia.org/wiki/Central_limit_theorem">Central Limit Theorem</a> to sums of Bernoulli random variables or directly use a classic result of <a href="https://en.wikipedia.org/wiki/De_Moivre%E2%80%93Laplace_theorem">de Moivre-Laplace</a>.</span>

The array of plots below shows the normal density superimposed on histograms of $\hat{w}$ for different values of $N$ and $w_0$. Observe that the normal approximation works better for large values of $N$ and away from pathological values of $w_0 = 0, 1$. 

![Normal approximation to binomial distribution](/2022-01-13/normal_approx_to_binom.png)


# A Broader Theory of MLE and Fisher Information



# Role of Statistical Learning Theory
The role of statistical learning theory is to clarify the performance of procedures like MLE we used above. 


# Conclusion
Performance measure should account for different $q$, model and the algorithm that computes $\hat{p}$. 